{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import newspaper\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "base_url = 'https://cyware.com/cyber-security-news-articles'\n",
    "categories_url = 'https://cyware.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('https://cyware.com/cyber-security-news-articles')\n",
    "tree = html.fromstring(resp.content)\n",
    "categories_elements = tree.xpath(\"/html/body/div/section/div/nav/ul/li/ul/div/li/a[@*]\")\n",
    "categories = {}\n",
    "\n",
    "for el in categories_elements:\n",
    "    categories[el.xpath('text()')[0].__str__()] = el.attrib['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = {}\n",
    "for idx, category in enumerate(list(categories.values())):\n",
    "    url = \"{}{}\".format(categories_url, category)\n",
    "    resp = requests.get(\"{}{}\".format(url, \"?p=15\"))\n",
    "    tree = html.fromstring(resp.content)\n",
    "    articles_elements = tree.xpath(\"/html/body/div[2]/main/section/div/div[1]/div[2]/div[1]/div/div/div/div/h2/a\")\n",
    "    articles[list(categories.keys())[idx]] = {el.xpath('text()')[0]:el.attrib['href'] for el in articles_elements}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"https://cyware.com/category/breaches-and-incidents-news?p=15\")\n",
    "tree = html.fromstring(resp.content)\n",
    "articles_elements = tree.xpath(\"/html/body/div[2]/main/section/div/div[1]/div[2]/div[1]/div/div/div/div/h2/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for category in list(articles.keys()):\n",
    "    for title in list(articles[category].keys()):\n",
    "        count+=1\n",
    "\n",
    "with tqdm(total=count) as pbar:\n",
    "    for category in list(articles.keys()):\n",
    "        for title in list(articles[category].keys()):\n",
    "            article_url = articles[category][title]\n",
    "            article = newspaper.Article(article_url)\n",
    "            article.download()\n",
    "            if article.download_state == 0:\n",
    "                time.sleep(3)\n",
    "            try:\n",
    "                article.parse()\n",
    "            except newspaper.ArticleException:\n",
    "                print(\"Article failed to download\\nUrl:{}\".format(article_url))\n",
    "            text = article.text\n",
    "            rows.append([category, categories[category], title, article_url, text])\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'POST'\n",
    "timestamp=int(time.time())+7200\n",
    "url = 'https://api.cyware.com/public/cyuserallstory/?l_time={}'.format(timestamp)\n",
    "raw_headers = \"User-Agent:PostmanRuntime/7.13.0\\nAccept:*/*\\nCache-Control:no-cache\\nPostman-Token:4ae3e87e-7195-4654-9bd9-ebe230359fb7\\ncookie:2fa_sessionid=fkk1a2qxxh0bc5cuxjmafezqjcjfgx6y\\ncontent-length:0\\nConnection:close\\nHost:api.cyware.com\"\n",
    "\n",
    "headers = dict([[h.partition(':')[0], h.partition(':')[2]] for h in raw_headers.split('\\n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "import datetime\n",
    "\n",
    "\n",
    "def fetch_and_analyze(el, api_page_url, next_api_page_url):\n",
    "    text = \"\"\n",
    "    \n",
    "    try:\n",
    "        if( \"{}{}\".format(el['url'], \"/\") == el['web_sp_link']):\n",
    "            text = el['text']\n",
    "        else:\n",
    "            url = el['web_sp_link']\n",
    "            article = newspaper.Article(url)\n",
    "            article.download()\n",
    "\n",
    "            max_time=0.0\n",
    "            while((article.download_state == 0) & (max_time < 2)):\n",
    "                time.sleep(0.1)\n",
    "                max_time += 0.1\n",
    "\n",
    "            article.parse()\n",
    "            text = article.text\n",
    "    except newspaper.ArticleException:\n",
    "        print(\"Article failed to download.\\nUrl:{}\\nTime: {}\".format(url, str(datetime.datetime.now())))\n",
    "    finally:   \n",
    "        return [text, el['title'],\n",
    "                      el['image'],\n",
    "                      el['category'],\n",
    "                      el['category_slug'],\n",
    "                      el['web_sp_link'],\n",
    "                      el['p_time'],\n",
    "                      api_page_url,\n",
    "                      next_api_page_url]\n",
    "\n",
    "articles_api = []\n",
    "\n",
    "resp = requests.request(method, url, headers=headers)\n",
    "json_content = json.loads(resp.text)\n",
    "count = int(json_content['count'])\n",
    "# count = 100\n",
    "num_cores = mp.cpu_count()\n",
    "\n",
    "with tqdm(total=count) as pbar:\n",
    "    while((len(articles_api) < count) & ((url != \"\") | (url != None))):\n",
    "        resp = requests.request(method, url, headers=headers)\n",
    "        json_content = json.loads(resp.text)\n",
    "        \n",
    "        api_page_url = url\n",
    "        next_api_page_url = json_content['links']['next']\n",
    "        url = next_api_page_url\n",
    "        \n",
    "        inputs = json_content['results']\n",
    "\n",
    "        rows = Parallel(n_jobs=num_cores)(delayed(fetch_and_analyze)(i, api_page_url, next_api_page_url) for i in inputs)\n",
    "        articles_api.extend(rows)\n",
    "        \n",
    "        pbar.update(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['text', 'title', 'image_url', 'category', 'category_slug', 'url', 'p_time', 'api_page_url', 'next_api_page_url']\n",
    "df = pd.DataFrame(articles_api, columns=columns)\n",
    "\n",
    "f = open('entries-cyware-api-2.csv', \"w\")\n",
    "df.to_csv(path_or_buf=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('entries-cyware-api-2-cleaned.csv', 'r')\n",
    "df = pd.read_csv(f, index_col=0)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 2, 3, 2, 3, 2, 2, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "# Solution Without Paralleization\n",
    "\n",
    "def howmany_within_range(row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "results = []\n",
    "for row in data:\n",
    "    results.append(howmany_within_range(row, minimum=4, maximum=8))\n",
    "\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
