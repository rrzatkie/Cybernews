{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported file: after-nlp-pipeline-09-16-2019-20-08-41.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c304b7f15f4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Successfully imported file: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_newest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-c304b7f15f4e>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmax_features_steps\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworker_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m                 \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'initializer'"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "worker_X = None\n",
    "worker_Y = None\n",
    "worker_min_df = None\n",
    "worker_max_df = None\n",
    "worker_stop_words = None\n",
    "\n",
    "def worker_init(X,Y,min_df,max_df,stop_words):\n",
    "    global worker_X\n",
    "    global worker_Y \n",
    "    global worker_min_df\n",
    "    global worker_max_df\n",
    "    global worker_stop_words\n",
    "    \n",
    "    worker_X = X\n",
    "    worker_Y = Y\n",
    "    worker_min_df = min_df\n",
    "    worker_max_df = max_df\n",
    "    worker_stop_words = stop_words\n",
    "\n",
    "def worker(max_features):\n",
    "    global worker_X\n",
    "    global worker_Y \n",
    "    global worker_min_df\n",
    "    global worker_max_df\n",
    "    global worker_stop_words\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features, stop_words=stop_words, min_df=worker_min_df, max_df=worker_max_df, ngram_range=(1,3))\n",
    "\n",
    "    feature_vector = tfidf_vectorizer.fit_transform(worker_X)\n",
    "    fill_ratio = feature_vector.nnz/(feature_vector.shape[0]*feature_vector.shape[1])\n",
    "    X_dense = feature_vector.todense()\n",
    "       \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_dense, worker_Y, test_size = 0.2)\n",
    "    clf = GaussianNB().fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    acc, num_acc, prec, recall = summarize_classification(y_test, y_pred)\n",
    "    \n",
    "    elapsed_time = time.time()-start_time\n",
    "    \n",
    "    stats_row = {}\n",
    "    stats_row['min_df'] = worker_min_df\n",
    "    stats_row['max_df'] = worker_max_df\n",
    "    stats_row['max_features'] = max_features\n",
    "    stats_row['fill_ratio'] = fill_ratio\n",
    "    stats_row['acc'] = acc\n",
    "    stats_row['acc_count'] = num_acc\n",
    "    stats_row['prec'] = prec\n",
    "    stats_row['recall'] = recall\n",
    "    stats_row['elapsed_time'] = elapsed_time\n",
    "    \n",
    "    return stats_row\n",
    "\n",
    "def summarize_classification(y_test, y_pred):\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return acc, num_acc, prec, recall\n",
    "\n",
    "def main(df):\n",
    "    df = df[['category', 'text_scraped', 'text_scraped_words_count', 'text_lemmatized']]\n",
    "    \n",
    "    df_filtered = pd.DataFrame(columns=['text_scraped', 'category', 'text_scraped_words_count'])\n",
    "    \n",
    "    for item in df.category.value_counts().items():\n",
    "        if(item[1] > 1000):\n",
    "            df_filtered = df_filtered.append(df[df.category.str.contains(item[0])][0:1000][['text_lemmatized', 'category']])\n",
    "    df = df_filtered\n",
    "    \n",
    "    wnl = WordNetLemmatizer()\n",
    "    X = [\" \".join([wnl.lemmatize(token) for token in text]) for text in df.text_lemmatized]\n",
    "    Y = df.category \n",
    "    \n",
    "    stop_words = text.ENGLISH_STOP_WORDS.union(string.punctuation)\n",
    "    \n",
    "    min_df_steps = range(1,17,1)\n",
    "    max_df_steps = range(1000, 4200, 200)\n",
    "    max_features_steps = range(100, 1060, 60)\n",
    "\n",
    "    test_stats = pd.DataFrame(columns=['min_df', 'max_df', 'max_features', 'fill_ratio', 'acc', 'acc_count', 'prec', 'recall', 'elapsed_time'])\n",
    "\n",
    "    num_cores = 2\n",
    "    for min_df in min_df_steps:\n",
    "        for max_df in max_df_steps:        \n",
    "            inputs = [x for x in max_features_steps]\n",
    "            stats = []\n",
    "            with futures.ProcessPoolExecutor(max_workers=num_cores, initializer=worker_init, initargs=[X,Y,min_df,max_df,stop_words]) as pool:\n",
    "                rows = [row for row in pool.map(worker, inputs)]\n",
    "                stats.extend(rows)\n",
    "\n",
    "    test_stats = test_stats.append(stats)\n",
    "\n",
    "def get_newest_file(fn_list):\n",
    "    dates = []\n",
    "    for f in fn_list:\n",
    "        match = re.search(\"([0-9]{2}-[0-9]{2}-[0-9]{4}-[0-9]{2}-[0-9]{2}-[0-9]{2})\", f)\n",
    "        if(match is not None):\n",
    "            dates.append({'fileName': f, 'date': match.group()})\n",
    "    \n",
    "    dates = list(map(lambda x: {'fileName': x['fileName'], 'date': datetime.strptime(x['date'], \"%m-%d-%Y-%H-%M-%S\")}, dates))\n",
    "    dates.sort(key=lambda x: x['date'], reverse=True)\n",
    "    return dates[0]['fileName']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fn_list = os.listdir(\"data/after-nlp-pipeline\")\n",
    "    fn_newest = get_newest_file(fn_list)\n",
    "\n",
    "    f = open(\"data/after-nlp-pipeline/{}\".format(fn_newest), 'r', encoding=\"utf-8\")\n",
    "    df = pd.read_csv(f, index_col=0, converters={'text_scraped_words': lambda x: x[1:-1].replace(\"'\", \"\").split(', '),'text_lemmatized': lambda x: x[1:-1].replace(\"'\", \"\").split(', ') })\n",
    "    f.close()\n",
    "    \n",
    "    print(\"Successfully imported file: {}\".format(fn_newest))\n",
    "    \n",
    "    main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/10-04-2019-16-12-49-stats.csv\", 'r', encoding=\"utf-8\")\n",
    "df = pd.read_csv(f, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fill_ratio = df.fill_ratio.max()\n",
    "max_recall = df.recall.max()\n",
    "max_prec = df.prec.max()\n",
    "max_acc = df.acc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for max fill_ratio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>max_features</th>\n",
       "      <th>fill_ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_count</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>1057</td>\n",
       "      <td>0.365868</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>21.806870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.386786</td>\n",
       "      <td>1083</td>\n",
       "      <td>0.375574</td>\n",
       "      <td>0.386786</td>\n",
       "      <td>21.563884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.379286</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.369003</td>\n",
       "      <td>0.379286</td>\n",
       "      <td>21.681530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>4</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>1089</td>\n",
       "      <td>0.374859</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>21.788196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>5</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.369286</td>\n",
       "      <td>1034</td>\n",
       "      <td>0.357891</td>\n",
       "      <td>0.369286</td>\n",
       "      <td>21.875518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>6</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.384643</td>\n",
       "      <td>1077</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.384643</td>\n",
       "      <td>21.973632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>7</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.385357</td>\n",
       "      <td>1079</td>\n",
       "      <td>0.370529</td>\n",
       "      <td>0.385357</td>\n",
       "      <td>21.734120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>8</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.382857</td>\n",
       "      <td>1072</td>\n",
       "      <td>0.372834</td>\n",
       "      <td>0.382857</td>\n",
       "      <td>22.657448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>9</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.383214</td>\n",
       "      <td>1073</td>\n",
       "      <td>0.370644</td>\n",
       "      <td>0.383214</td>\n",
       "      <td>22.215764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>10</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.389643</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.380847</td>\n",
       "      <td>0.389643</td>\n",
       "      <td>21.679076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>11</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.376071</td>\n",
       "      <td>1053</td>\n",
       "      <td>0.368828</td>\n",
       "      <td>0.376071</td>\n",
       "      <td>22.876546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>12</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>1036</td>\n",
       "      <td>0.354835</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>22.191293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>13</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.386786</td>\n",
       "      <td>1083</td>\n",
       "      <td>0.377607</td>\n",
       "      <td>0.386786</td>\n",
       "      <td>22.600192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>14</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.378929</td>\n",
       "      <td>1061</td>\n",
       "      <td>0.367832</td>\n",
       "      <td>0.378929</td>\n",
       "      <td>21.956773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>15</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1064</td>\n",
       "      <td>0.368726</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>22.063359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.228021</td>\n",
       "      <td>0.377143</td>\n",
       "      <td>1056</td>\n",
       "      <td>0.366804</td>\n",
       "      <td>0.377143</td>\n",
       "      <td>22.159949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      min_df  max_df  max_features  fill_ratio       acc  acc_count      prec  \\\n",
       "240        1    4000           100    0.228021  0.377500       1057  0.365868   \n",
       "496        2    4000           100    0.228021  0.386786       1083  0.375574   \n",
       "752        3    4000           100    0.228021  0.379286       1062  0.369003   \n",
       "1008       4    4000           100    0.228021  0.388929       1089  0.374859   \n",
       "1264       5    4000           100    0.228021  0.369286       1034  0.357891   \n",
       "1520       6    4000           100    0.228021  0.384643       1077  0.375900   \n",
       "1776       7    4000           100    0.228021  0.385357       1079  0.370529   \n",
       "2032       8    4000           100    0.228021  0.382857       1072  0.372834   \n",
       "2288       9    4000           100    0.228021  0.383214       1073  0.370644   \n",
       "2544      10    4000           100    0.228021  0.389643       1091  0.380847   \n",
       "2800      11    4000           100    0.228021  0.376071       1053  0.368828   \n",
       "3056      12    4000           100    0.228021  0.370000       1036  0.354835   \n",
       "3312      13    4000           100    0.228021  0.386786       1083  0.377607   \n",
       "3568      14    4000           100    0.228021  0.378929       1061  0.367832   \n",
       "3824      15    4000           100    0.228021  0.380000       1064  0.368726   \n",
       "4080      16    4000           100    0.228021  0.377143       1056  0.366804   \n",
       "\n",
       "        recall  elapsed_time  \n",
       "240   0.377500     21.806870  \n",
       "496   0.386786     21.563884  \n",
       "752   0.379286     21.681530  \n",
       "1008  0.388929     21.788196  \n",
       "1264  0.369286     21.875518  \n",
       "1520  0.384643     21.973632  \n",
       "1776  0.385357     21.734120  \n",
       "2032  0.382857     22.657448  \n",
       "2288  0.383214     22.215764  \n",
       "2544  0.389643     21.679076  \n",
       "2800  0.376071     22.876546  \n",
       "3056  0.370000     22.191293  \n",
       "3312  0.386786     22.600192  \n",
       "3568  0.378929     21.956773  \n",
       "3824  0.380000     22.063359  \n",
       "4080  0.377143     22.159949  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df[df.fill_ratio==max_fill_ratio]\n",
    "print(\"Parameters for max fill_ratio\")\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for max recall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>max_features</th>\n",
       "      <th>fill_ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_count</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>880</td>\n",
       "      <td>0.098756</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>1367</td>\n",
       "      <td>0.481306</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>22.343998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.091371</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>1367</td>\n",
       "      <td>0.483705</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>22.502659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     min_df  max_df  max_features  fill_ratio       acc  acc_count      prec  \\\n",
       "253       1    4000           880    0.098756  0.488214       1367  0.481306   \n",
       "767       3    4000          1000    0.091371  0.488214       1367  0.483705   \n",
       "\n",
       "       recall  elapsed_time  \n",
       "253  0.488214     22.343998  \n",
       "767  0.488214     22.502659  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df[df.recall==max_recall]\n",
    "print(\"Parameters for max recall\")\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for max prec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>max_features</th>\n",
       "      <th>fill_ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_count</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>4</td>\n",
       "      <td>3400</td>\n",
       "      <td>940</td>\n",
       "      <td>0.087392</td>\n",
       "      <td>0.482857</td>\n",
       "      <td>1352</td>\n",
       "      <td>0.484313</td>\n",
       "      <td>0.482857</td>\n",
       "      <td>22.579051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     min_df  max_df  max_features  fill_ratio       acc  acc_count      prec  \\\n",
       "974       4    3400           940    0.087392  0.482857       1352  0.484313   \n",
       "\n",
       "       recall  elapsed_time  \n",
       "974  0.482857     22.579051  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df[df.prec==max_prec]\n",
    "print(\"Parameters for max prec\")\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters for max acc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_df</th>\n",
       "      <th>max_features</th>\n",
       "      <th>fill_ratio</th>\n",
       "      <th>acc</th>\n",
       "      <th>acc_count</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>880</td>\n",
       "      <td>0.098756</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>1367</td>\n",
       "      <td>0.481306</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>22.343998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>3</td>\n",
       "      <td>4000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.091371</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>1367</td>\n",
       "      <td>0.483705</td>\n",
       "      <td>0.488214</td>\n",
       "      <td>22.502659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     min_df  max_df  max_features  fill_ratio       acc  acc_count      prec  \\\n",
       "253       1    4000           880    0.098756  0.488214       1367  0.481306   \n",
       "767       3    4000          1000    0.091371  0.488214       1367  0.483705   \n",
       "\n",
       "       recall  elapsed_time  \n",
       "253  0.488214     22.343998  \n",
       "767  0.488214     22.502659  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df[df.acc==max_acc]\n",
    "print(\"Parameters for max acc\")\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "from concurrent import futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'text_lemmatized'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-5fe507f8eb41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwnl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwnl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_lemmatized\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\cybernews\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5179\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5180\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'text_lemmatized'"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "X = [\" \".join([wnl.lemmatize(token) for token in text]) for text in df.text_lemmatized]\n",
    "Y = df.category \n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(string.punctuation)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features, stop_words=stop_words, min_df=min_df, max_df=max_df, ngram_range=(1,3))\n",
    "\n",
    "feature_vector = tfidf_vectorizer.fit_transform(X)\n",
    "fill_ratio = feature_vector.nnz/(feature_vector.shape[0]*feature_vector.shape[1])\n",
    "X_dense = feature_vector.todense()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_dense, Y, test_size = 0.2)\n",
    "clf = GaussianNB().fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc, num_acc, prec, recall = summarize_classification(y_test, y_pred)\n",
    "acc, num_acc, prec, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
